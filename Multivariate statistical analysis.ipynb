{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a22255",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Firstly, let's load the bank-additional-full.csv data and perform some exploratory data analysis on it. In Python, we can use the Pandas library to load and manipulate datasets. Here's  code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1b4a585",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "               age      duration      campaign         pdays      previous  \\\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
      "\n",
      "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
      "count  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  \n",
      "mean       0.081886       93.575664     -40.502600      3.621291   5167.035911  \n",
      "std        1.570960        0.578840       4.628198      1.734447     72.251528  \n",
      "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
      "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
      "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
      "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
      "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('bank-additional-full.csv')\n",
    "\n",
    "# Print the first 5 rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Get descriptive statistics of the numerical variables\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797d45c",
   "metadata": {},
   "source": [
    "The above code will load the dataset, print the first 5 rows, check for missing values, and get descriptive statistics of the numerical variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707381b9",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "\n",
    "Next, we need to encode the categorical variables using label encoding. Label encoding is a process of converting categorical variables into numerical form so that they can be used in machine learning models. In Python, we can use Scikit-learn's LabelEncoder class to perform label encoding. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6ba2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
      "0   56    3        1          0        0        0     0        1      6   \n",
      "1   57    7        1          3        1        0     0        1      6   \n",
      "2   37    7        1          3        0        2     0        1      6   \n",
      "3   40    0        1          1        0        0     0        1      6   \n",
      "4   56    7        1          3        0        0     2        1      6   \n",
      "\n",
      "   day_of_week  ...  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
      "0            1  ...         1    999         0         1           1.1   \n",
      "1            1  ...         1    999         0         1           1.1   \n",
      "2            1  ...         1    999         0         1           1.1   \n",
      "3            1  ...         1    999         0         1           1.1   \n",
      "4            1  ...         1    999         0         1           1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
      "0          93.994          -36.4      4.857       5191.0  0  \n",
      "1          93.994          -36.4      4.857       5191.0  0  \n",
      "2          93.994          -36.4      4.857       5191.0  0  \n",
      "3          93.994          -36.4      4.857       5191.0  0  \n",
      "4          93.994          -36.4      4.857       5191.0  0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the categorical variables\n",
    "data['job'] = le.fit_transform(data['job'])\n",
    "data['marital'] = le.fit_transform(data['marital'])\n",
    "data['education'] = le.fit_transform(data['education'])\n",
    "data['default'] = le.fit_transform(data['default'])\n",
    "data['housing'] = le.fit_transform(data['housing'])\n",
    "data['loan'] = le.fit_transform(data['loan'])\n",
    "data['contact'] = le.fit_transform(data['contact'])\n",
    "data['month'] = le.fit_transform(data['month'])\n",
    "data['day_of_week'] = le.fit_transform(data['day_of_week'])\n",
    "data['poutcome'] = le.fit_transform(data['poutcome'])\n",
    "data['y'] = le.fit_transform(data['y'])\n",
    "\n",
    "# Print the first 5 rows of the dataset after encoding\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4c22a",
   "metadata": {},
   "source": [
    "The above code will create a LabelEncoder object, encode the categorical variables, and print the first 5 rows of the dataset after encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584203fc",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "After encoding the dataset, the next step is to split the data into training and testing sets. In Python, we can use Scikit-learn's train_test_split function to perform this operation. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d5fec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (26772, 20) (26772,)\n",
      "Testing set shape: (14416, 20) (14416,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X (features) and y (target)\n",
    "X = data.drop('y', axis=1)\n",
    "y = data['y']\n",
    "\n",
    "# Split the data into training and testing sets with a 65:35 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83acada7",
   "metadata": {},
   "source": [
    "## randomization  ðŸ‘†\n",
    "\n",
    "`random_state = 42` is a parameter commonly used in machine learning algorithms, including scikit-learn, to ensure reproducibility of the results. When this parameter is set to a specific value, such as 42, it will initialize the random number generator used by the algorithm with this seed value. This means that every time the algorithm is run with the same seed value, it will produce the same sequence of random numbers, which in turn will result in the same set of outputs.\n",
    "\n",
    "The way the randomization occurs depends on the specific algorithm being used. However, in general, the algorithm will use a pseudo-random number generator (PRNG) to generate a sequence of apparently random numbers based on a predetermined algorithm. The PRNG generates these numbers deterministically, based on an initial seed value and a mathematical formula, so they are not truly random. However, the resulting sequence appears to be random for practical purposes.\n",
    "\n",
    "By setting the `random_state` parameter to a fixed value, we can ensure that the same sequence of \"random\" numbers is generated each time we run the algorithm. This can be useful for testing and debugging, as well as ensuring that results are consistent across different runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3fec1",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "Now that we have our training and testing sets, we can build a logistic regression model. Logistic regression is a method for analyzing a dataset in which there are one or more independent variables that determine an outcome. It is commonly used for binary classification problems. In Python, we can use Scikit-learn's LogisticRegression class to build the model. Here's The code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f05f51bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9088512763596004\n",
      "The coefficients are: [[ 0.00190464  0.02648694  0.02244785  0.09336503 -0.0258161   0.00675698\n",
      "  -0.00245879 -0.04032106 -0.03759216  0.02210143  0.00456907 -0.079183\n",
      "  -0.00164802  0.01626544  0.00058085 -0.26201575  0.19371844  0.04785373\n",
      "  -0.27560908 -0.00349051]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parsa/miniconda3/envs/ai/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression object\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model using the training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Find the coefficients\n",
    "coefs = lr.coef_\n",
    "\n",
    "# Predict the target variable using the testing data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Print the accuracy score of the model\n",
    "print(\"Accuracy score:\", lr.score(X_test, y_test))\n",
    "print(\"The coefficients are: {}\".format(coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03a085",
   "metadata": {},
   "source": [
    "The above code will create a Logistic Regression object, fit the model using the training data, predict the target variable using the testing data, and print the accuracy score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a41d4",
   "metadata": {},
   "source": [
    "# Summary of the Model\n",
    "\n",
    "We can get a summary of the logistic regression model using the statsmodels library. Here's The example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eeab948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7400dd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.214037\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                26772\n",
      "Model:                          Logit   Df Residuals:                    26751\n",
      "Method:                           MLE   Df Model:                           20\n",
      "Date:                Fri, 23 Jun 2023   Pseudo R-squ.:                  0.3907\n",
      "Time:                        20:52:24   Log-Likelihood:                -5730.2\n",
      "converged:                       True   LL-Null:                       -9403.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const            -10.6339     23.920     -0.445      0.657     -57.517      36.249\n",
      "age                0.0017      0.002      0.733      0.464      -0.003       0.006\n",
      "job                0.0020      0.007      0.292      0.770      -0.012       0.016\n",
      "marital            0.0503      0.045      1.123      0.261      -0.037       0.138\n",
      "education          0.0449      0.012      3.673      0.000       0.021       0.069\n",
      "default           -0.3532      0.081     -4.342      0.000      -0.513      -0.194\n",
      "housing           -0.0312      0.025     -1.238      0.216      -0.081       0.018\n",
      "loan              -0.0139      0.035     -0.404      0.686      -0.082       0.054\n",
      "contact           -0.7680      0.080     -9.584      0.000      -0.925      -0.611\n",
      "month             -0.1134      0.012     -9.724      0.000      -0.136      -0.091\n",
      "day_of_week        0.0635      0.018      3.530      0.000       0.028       0.099\n",
      "duration           0.0045   8.99e-05     50.078      0.000       0.004       0.005\n",
      "campaign          -0.0442      0.014     -3.086      0.002      -0.072      -0.016\n",
      "pdays             -0.0011      0.000     -5.429      0.000      -0.001      -0.001\n",
      "previous          -0.0758      0.069     -1.099      0.272      -0.211       0.059\n",
      "poutcome           0.4230      0.095      4.447      0.000       0.237       0.609\n",
      "emp.var.rate      -1.0436      0.085    -12.336      0.000      -1.209      -0.878\n",
      "cons.price.idx     0.7980      0.148      5.391      0.000       0.508       1.088\n",
      "cons.conf.idx      0.0155      0.008      1.855      0.064      -0.001       0.032\n",
      "euribor3m          0.7583      0.127      5.993      0.000       0.510       1.006\n",
      "nr.employed       -0.0134      0.002     -5.893      0.000      -0.018      -0.009\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add a constant column to the X_train dataset\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Create a Logistic Regression object using statsmodels\n",
    "lr_sm = sm.Logit(y_train, X_train_sm)\n",
    "\n",
    "# Fit the model using the training data\n",
    "lr_sm_fit = lr_sm.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lr_sm_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008ddf2",
   "metadata": {},
   "source": [
    "# Discriminant Analysis\n",
    "\n",
    "Another classification method we can use is discriminant analysis. Discriminant analysis is a statistical technique used to identify the underlying factors that differentiate between two or more groups. In Python, we can use Scikit-learn's LinearDiscriminantAnalysis class to perform discriminant analysis. Here's theexample code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "816bb2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9070477247502775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create a Linear Discriminant Analysis object\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model using the training data\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable using the testing data\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "\n",
    "# Print the accuracy score of the model\n",
    "print(\"Accuracy score:\", lda.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9669e0",
   "metadata": {},
   "source": [
    "The above code will create a Linear Discriminant Analysis object, fit the model using the training data, predict the target variable using the testing data, and print the accuracy score of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46266a8",
   "metadata": {},
   "source": [
    "# Evaluation of the Model\n",
    "\n",
    "To evaluate the performance of the logistic regression and discriminant analysis models, we can use metrics such as accuracy score, precision, recall, and F1-score. In Python, we can use Scikit-learn's classification_report function to get these metrics. Here's an example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec4d9409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     12782\n",
      "           1       0.66      0.40      0.50      1634\n",
      "\n",
      "    accuracy                           0.91     14416\n",
      "   macro avg       0.79      0.69      0.73     14416\n",
      "weighted avg       0.90      0.91      0.90     14416\n",
      "\n",
      "Linear Discriminant Analysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     12782\n",
      "           1       0.61      0.48      0.54      1634\n",
      "\n",
      "    accuracy                           0.91     14416\n",
      "   macro avg       0.78      0.72      0.74     14416\n",
      "weighted avg       0.90      0.91      0.90     14416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report for logistic regression model\n",
    "print(\"Logistic Regression\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the classification report for LDA model\n",
    "print(\"Linear Discriminant Analysis\")\n",
    "print(classification_report(y_test, y_pred_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe80b0",
   "metadata": {},
   "source": [
    "The above code will print the classification report for both the logistic regression and LDA models. The classification report includes information such as precision, recall, F1-score, and support for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
